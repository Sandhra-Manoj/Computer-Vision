{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b125f3eb",
   "metadata": {
    "id": "b125f3eb"
   },
   "source": [
    "# Face recognition and Face detection using the OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce5d2a2",
   "metadata": {
    "id": "9ce5d2a2"
   },
   "source": [
    "The face recognition is a technique to identify or verify the face from the digital images or video frame. A human can quickly identify the faces without much effort. It is an effortless task for us, but it is a difficult task for a computer. There are various complexities, such as low resolution, occlusion, illumination variations, etc. These factors highly affect the accuracy of the computer to recognize the face more effectively. First, it is necessary to understand the difference between face detection and face recognition.\n",
    "\n",
    "### Face Detection: The face detection is generally considered as finding the faces (location and size) in an image and probably extract them to be used by the face detection algorithm.\n",
    "\n",
    "### Face Recognition: The face recognition algorithm is used in finding features that are uniquely described in the image. The facial image is already extracted, cropped, resized, and usually converted in the grayscale.\n",
    "\n",
    "There are various algorithms of face detection and face recognition. Here we will learn about face detection using the HAAR cascade algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107764c6",
   "metadata": {
    "id": "107764c6"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "133a819d",
   "metadata": {
    "id": "133a819d"
   },
   "source": [
    "### The 3 Phases\n",
    "\n",
    "To create a complete project on Face Recognition, we must work on 3 very distinct phases:\n",
    "\n",
    "    .Face Detection and Data Gathering\n",
    "    .Train the Recognizer\n",
    "    .Face Recognition\n",
    "    \n",
    "The below block diagram resumes those phases:\n",
    "![image.png](attachment:image.png)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab10ab9",
   "metadata": {
    "id": "0ab10ab9"
   },
   "source": [
    "## Face Detection\n",
    "\n",
    "The most basic task on Face Recognition is of course, “Face Detecting”. Before anything, you must “capture” a face in order to recognize it, when compared with a new face captured on future.\n",
    "\n",
    "The most common way to detect a face (or any objects), is using the “Haar Cascade classifier”\n",
    "\n",
    "Object Detection using Haar feature-based cascade classifiers is an effective object detection method.It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images.\n",
    "\n",
    "Here we will work with face detection. Initially, the algorithm needs a lot of positive images (images of faces) and negative images (images without faces) to train the classifier. Then we need to extract features from it. The good news is that OpenCV comes with a trainer as well as a detector. If you want to train your own classifier for any object like car, planes etc. you can use OpenCV to create one.\n",
    "\n",
    "If you do not want to create your own classifier, OpenCV already contains many pre-trained classifiers for face, eyes, smile, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e1c056",
   "metadata": {
    "id": "e8e1c056"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file dataset already exists.\n"
     ]
    }
   ],
   "source": [
    "mkdir dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bec43e11",
   "metadata": {
    "id": "bec43e11"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "col = ['ID','NAME']\n",
    "\n",
    "with open('Person_Detailss.csv', 'a+') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerow(col)\n",
    "            csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638afed0",
   "metadata": {},
   "source": [
    "#### Transfer learning : leveraging knowledge from a pre-trained model on a large dataset to improve performance of a model on a new related task.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2646d63",
   "metadata": {
    "id": "d2646d63",
    "outputId": "02765217-d3eb-49c5-8a95-fc8278e75dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " enter user id end press <return> ==>  1\n",
      "\n",
      " enter your name end press <return> ==>  sandhra\n",
      "\n",
      " [INFO] Initializing face capture. Look the camera and wait ...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video width\n",
    "cam.set(4, 480) # set video height\n",
    "\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') #transfer learning\n",
    "\n",
    "# For each person, enter one numeric face id\n",
    "face_id = input('\\n enter user id end press <return> ==>  ')\n",
    "face_name = input('\\n enter your name end press <return> ==>  ')\n",
    "print(\"\\n [INFO] Initializing face capture. Look the camera and wait ...\")\n",
    "\n",
    "# Initialize individual sampling face count\n",
    "count = 0\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_detector.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        count += 1\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"dataset/\" + str(face_name) + '.' +str(face_id) + '.' +\n",
    "                    str(count) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "        cv2.imshow('image', img)\n",
    "    k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif count >= 30: # Take 30 face sample and stop video\n",
    "         break\n",
    "\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "row = [face_id, face_name]\n",
    "with open('Person_Detailss.csv', 'a+') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerow(row)\n",
    "            csvFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2804e35",
   "metadata": {
    "id": "b2804e35"
   },
   "source": [
    "Now we must call our classifier function, passing it some very important parameters, as scale factor, number of neighbors and minimum size of the detected face.\n",
    "\n",
    "faces = faceCascade.detectMultiScale(\n",
    "\n",
    "        gray,     \n",
    "        scaleFactor=1.2,\n",
    "        minNeighbors=5,     \n",
    "        minSize=(20, 20)\n",
    "        )\n",
    "Where,\n",
    "\n",
    "gray is the input grayscale image.\n",
    "\n",
    "scaleFactor is the parameter specifying how much the image size is reduced at each image scale. It is used to create the scale pyramid.\n",
    "\n",
    "minNeighbors is a parameter specifying how many neighbors each candidate rectangle should have, to retain it. A higher number gives lower false positives.\n",
    "\n",
    "minSize is the minimum rectangle size to be considered a face.\n",
    "\n",
    "The function will detect faces on the image. Next, we must “mark” the faces in the image, using, for example, a blue rectangle. This is done with this portion of the code:\n",
    "\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "    \n",
    "If faces are found, it returns the positions of detected faces as a rectangle with the left up corner (x,y) and having “w” as its Width and “h” as its Height ==> (x,y,w,h)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84df21f8",
   "metadata": {
    "id": "84df21f8"
   },
   "source": [
    "## Trainer\n",
    "\n",
    "On this second phase, we must take all user data from our dataset and “trainer” the OpenCV Recognizer. This is done directly by a specific OpenCV function. The result will be a .yml file that will be saved on a “trainer/” directory.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "So, let’s start creating a subdirectory where we will store the trained data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1594114b",
   "metadata": {
    "id": "1594114b"
   },
   "outputs": [],
   "source": [
    "mkdir trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516c6cb2",
   "metadata": {
    "id": "516c6cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\dell\\anaconda3\\lib\\site-packages (9.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc7a544",
   "metadata": {
    "id": "0dc7a544",
    "outputId": "e09ea216-7b24-4c58-ac88-990da87f4830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [INFO] Training faces. It will take a few seconds. Wait ...\n",
      "\n",
      " [INFO] 1 faces trained. Exiting Program\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "# Path for face image database\n",
    "path = 'dataset'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\");\n",
    "\n",
    "# function to get the images and label data\n",
    "def getImagesAndLabels(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]\n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    for imagePath in imagePaths:\n",
    "        PIL_img = Image.open(imagePath).convert('L') # grayscale\n",
    "        img_numpy = np.array(PIL_img,'uint8')\n",
    "        id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "\n",
    "        faces = detector.detectMultiScale(img_numpy)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    return faceSamples,ids\n",
    "\n",
    "print (\"\\n [INFO] Training faces. It will take a few seconds. Wait ...\")\n",
    "faces,ids = getImagesAndLabels(path)\n",
    "\n",
    "recognizer.train(faces, np.array(ids))\n",
    "\n",
    "# Save the model into trainer/trainer.yml\n",
    "recognizer.write('trainer/trainer.yml')\n",
    "\n",
    "# Print the numer of faces trained and end program\n",
    "print(\"\\n [INFO] {0} faces trained. Exiting Program\".format(len(np.unique(ids))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3668bf64",
   "metadata": {
    "id": "3668bf64"
   },
   "source": [
    "We will use as a recognizer, the LBPH (LOCAL BINARY PATTERNS HISTOGRAMS) Face Recognizer, included on OpenCV package to detect faces. It labels the pixels of an image by thresholding the neighborhood of each pixel and considers the result as a binary number.\n",
    "\n",
    "\n",
    "The model built is trained with the faces with tag given to them, and later on, the machine is given a test data and machine decides the correct label for it.\n",
    "\n",
    "\n",
    "The function “getImagesAndLabels (path)”, will take all photos on directory: “dataset/”, returning 2 arrays: “Ids” and “faces”. With those arrays as input, we will “train our recognizer”:\n",
    "\n",
    "    .recognizer.train(faces, ids)\n",
    "\n",
    "As a result, a file named “trainer.yml” will be saved in the trainer directory that was previously created by us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af450b",
   "metadata": {
    "id": "48af450b"
   },
   "source": [
    "## Recognizer\n",
    "\n",
    "Now, we reached the final phase of our project. Here, we will capture a fresh face on our camera and if this person had his face captured and trained before, our recognizer will make a “prediction” returning its id and an index, shown how confident the recognizer is with this match.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9aa2ed",
   "metadata": {
    "id": "7d9aa2ed",
    "outputId": "46db7585-c5e7-4f33-99f8-6706ebb056d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [INFO] Exiting Program and cleanup stuff\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('trainer/trainer.yml')\n",
    "\n",
    "cascadePath = \"haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath);\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "#iniciate id counter\n",
    "id = 0\n",
    "# Initialize and start realtime video capture\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video widht\n",
    "cam.set(4, 480) # set video height\n",
    "# Define min window size to be recognized as a face\n",
    "\n",
    "minW = 0.1*cam.get(3)\n",
    "minH = 0.1*cam.get(4)\n",
    "\n",
    "df = pd.read_csv(\"Person_Detailss.csv\")\n",
    "\n",
    "while True:\n",
    "    ret, img =cam.read()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor = 1.2,\n",
    "        minNeighbors = 5,\n",
    "        minSize = (int(minW), int(minH))\n",
    "       )\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "\n",
    "        id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "\n",
    "        text = df.loc[df['ID'] == id]['NAME'].values\n",
    "\n",
    "         # If confidence is less them 100 ==> \"0\" : perfect match\n",
    "        if (confidence < 100):\n",
    "            id = text[0]\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        else:\n",
    "            id = \"unknown\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "\n",
    "        cv2.putText(\n",
    "                    img,\n",
    "                    str(id),\n",
    "                    (x+5,y-5),\n",
    "                    font,\n",
    "                    1,\n",
    "                    (255,255,255),\n",
    "                    2\n",
    "                   )\n",
    "        cv2.putText(\n",
    "                    img,\n",
    "                    str(confidence),\n",
    "                    (x+5,y+h-5),\n",
    "                    font,\n",
    "                    1,\n",
    "                    (255,255,0),\n",
    "                    1\n",
    "                   )\n",
    "\n",
    "    cv2.imshow('camera',img)\n",
    "    k = cv2.waitKey(0) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe252a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95becfe4",
   "metadata": {
    "id": "bc6591db"
   },
   "source": [
    "You can also include classifiers for “eyes detection” or even “smile detection”. On those cases, you will include the classifier function and rectangle draw inside the face loop, because would be no sense to detect an eye or a smile outside of a face.\n",
    "\n",
    "image.png"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
